import matplotlib.pyplot as plt
import os 
from abc import ABC
from functools import partial
import numpy as np
import pandas as pd
import glob
import subprocess
import re 
import json

import bilby
import scipy
from matplotlib import colors
import scipy.stats
from chainconsumer import ChainConsumer
from pesummary.gw.conversions import convert

from dingo.gw.domains import build_domain, build_domain_from_model_metadata
from dingo.gw.result import Result
from dingo.core.models import PosteriorModel
from dingo.gw.inference.gw_samplers import GWSamplerGNPE, GWSampler


def get_snr(domain, asd, strain_data, duration=8.0):
    """
    Given an injection generated by Injection.injection or Injection.random_injection
    will return snr of the injection in the two detectors

    Returns
    -------
    dict
        keys:
            detector: data (signal + noise) in each detector
    """
    snrs = {k: None for k in strain_data["waveform"].keys()}
    freq_snr_squared = {k: None for k in strain_data["waveform"].keys()}

    for ifo_name, ifo_signal in strain_data["waveform"].items():

        integrand = (np.conj(ifo_signal) * ifo_signal) / (
            (asd[ifo_name] ** 2) * domain.window_factor
        )
        freq_snr_squared[ifo_name] = (4 / duration) * integrand
        snrs[ifo_name] = ((4 / duration) * np.sum(integrand)) ** 0.5

    network_snr = np.sqrt(
        sum([snrs[ifo_name] ** 2 for ifo_name in strain_data["waveform"].keys()])
    )
    return snrs, freq_snr_squared, network_snr


def find_file_with_suffix(folder_path, file_suffix):
    search_pattern = os.path.join(folder_path, f'*{file_suffix}')
    matching_files = glob.glob(search_pattern)

    if matching_files:
        return matching_files[0]
    else:
        return None

def find_files_with_extension(directory, extension):
    pattern = os.path.join(directory, f"*.{extension}")
    matching_files = glob.glob(pattern)
    return matching_files

class PosteriorList:
    """ 
    Class which is used to store posteriors from dingo analyses. This will store both
    the injected value and the recovered posterior samples 
    """
    def __init__(self):
        self.master_dict = {}

    def append_var(self, var):
        self.master_dict[var] = {"truth": None, "posteriors": None, "snr": None, "ess": None, "kl": None}

    def append_posterior(self, var, new_posterior):
        if isinstance(new_posterior, pd.DataFrame) or isinstance(new_posterior, pd.Series):
            new_posterior = new_posterior.to_dict("list")
        
        # commented because slow
        # self.master_dict[var]["posteriors"] = pd.DataFrame(convert(new_posterior))
        self.master_dict[var]["posteriors"] = pd.DataFrame(new_posterior)

    def append_truth(self, var, truth):
        if isinstance(truth, pd.DataFrame) or isinstance(truth, pd.Series):
            truth = truth.to_dict()
        self.master_dict[var]["truth"] = pd.DataFrame(convert(truth))

    def append_snr(self, var, snr):
        self.master_dict[var]["snr"] = snr

    def append_ess(self, var, ess, sample_efficiency):
        self.master_dict[var]["ess"] = {
            "effective_sample_size": ess,
            "sample_efficiency": sample_efficiency
        }

    def append_kl_divergence(self, var, kl_divergence, kl_divergence_variance):
        self.master_dict[var]["kl"] = {"kl_divergence": kl_divergence, "kl_divergence_variance": kl_divergence_variance}

    def __getitem__(self, idx):
        var = list(self.master_dict.keys())[idx]
        return self.get_item_var(var)

    def get_item_var(self, var):
        return self.master_dict[var]
    
    def get_mean(self, idx):
        posterior = self[idx]["posteriors"]
        ret = posterior.mean()
        return ret

    def get_median(self, idx):
        posterior = self[idx]["posteriors"]
        ret = posterior.median()
        return ret

    def get_std(self, idx):
        posterior = self[idx]["posteriors"]
        ret = posterior.std()
        return ret

    def get_interval(self, idx, interval=0.9):
        samples = self[idx]["posteriors"] 

        # Generating 90% interval
        unnorm_prob = samples["log_likelihood"] + samples["log_prior"]
        log_prob_sum = np.logaddexp.reduce(unnorm_prob)
        log_prob_target = unnorm_prob - log_prob_sum
        samples["log_prob_target"] = log_prob_target
        samples = samples.sort_values("log_prob_target")
        log_cdf = np.logaddexp.accumulate(log_prob_target)
        n_cutoff = np.searchsorted(log_cdf, np.log(1 - interval))
        interval_samples = samples.iloc[n_cutoff:]
        ret = interval_samples.agg(['min','max'])
        return ret

    def __len__(self):
        return len(self.master_dict)

    @property 
    def keys_array(self):
        return np.array(list(self.master_dict.keys()))

    @property
    def index_vars(self):
        return list(self.master_dict.keys())


class Bias(ABC):
    def __init__(self, sampler_settings, _injection_parameters):
        self.sampler_settings = sampler_settings
        self.injection_parameters = _injection_parameters

    @property
    def injection_parameters(self):
        # There are additional injection parameters which can be derived
        ret = pd.DataFrame(convert(self._injection_parameters.to_dict("list")))
        return ret

    @injection_parameters.setter
    def injection_parameters(self, _injection_parameters):
        # TODO implement arbitrary parameters that transform
        if isinstance(_injection_parameters, dict):
            self._injection_parameters = pd.DataFrame({
                k: v * np.ones(self.length) for k, v in _injection_parameters.items()
            })
        else:
            self._injection_parameters = _injection_parameters

    def check_prior(self, sweep_params):
        raise NotImplementedError
        # NOTE NOTE NOTE this function is BROKEN RIGHT NOW NOT EVEN CHECKING PRIORS!
        tmp_result = self.sampler.to_result()
        prior = tmp_result.prior
        for param_name, sweep_array in params.items():
            if not param_name in list(prior.keys()):
                print(f"Parameter {param_name} not in prior")
            else:
                if sweep_array.min() < prior[param_name].minimum or sweep_array.max() > prior[param_name].maximum:
                    raise Exception(f"Parameter {param_name} not in prior range")

        return True

    def rescale_distance(self, target_snr):
        """
        Given a target network snr and parameters for a waveform, will rescale the luminosity distance, parameters["luminosity_distance"] such that now the network snr
        of the signal generated by parameters is the target_snr
        """

        def f(domain, parameters, injection_generator, target_snr, d_L):
            parameters["luminosity_distance"] = d_L
            _, _, network_snr = get_snr(
                domain, injection_generator.asd, injection_generator.signal(parameters)
            )
            opt = (target_snr - network_snr.real) ** 2
            return opt

        rescaled_injection_parameters = self.injection_parameters.copy()
        x0 = self.injection_parameters["luminosity_distance"][0]
        for idx, parameters in rescaled_injection_parameters.copy().iterrows():
            g = partial(
                f, self.domain, parameters, self.injection_generator, target_snr
            )
            res = scipy.optimize.minimize(g, x0=x0, tol=1e-2)
            x0 = res.x
            # param = {"luminosity_distance": np.array(res.x)}
            # self.check_prior(param)
            rescaled_injection_parameters["luminosity_distance"][idx] = res.x
        self._injection_parameters = rescaled_injection_parameters

    def from_folder(self, load_dir):
        """ 
        Parameters
        ----------
        load_dir : str 
            Directory which contains all importance sampled results 
        """
        
        # loading saved injection from folder  
        self.injection_parameters = pd.read_csv(os.path.join(load_dir, "injection_parameters.csv"))
        with open(os.path.join(load_dir, "sampler_settings.json"), 'r') as fp:
            self.sampler_settings = json.load(fp)


        # iterating through injection parameters and generating posterior list
        self.posterior_list = PosteriorList()
        for idx in range(self.length):
            result_dir = os.path.join(load_dir, f"outdir_{idx}", "result")
            file = find_file_with_suffix(result_dir, "importance_sampling.hdf5")
            result = Result(file_name=os.path.join(result_dir, file))

            # Record the sweep array value for each posterior, this serves as a key
            var = tuple(self.sweep_params.iloc[idx])
            self.posterior_list.append_var(var)

            # appending truth values
            self.posterior_list.append_truth(var, self.injection_parameters.iloc[idx])

            # appending posterior 
            self.posterior_list.append_posterior(var, result.pesummary_samples)

            # appending effective sample size
            self.posterior_list.append_ess(var, result.effective_sample_size, result.sample_efficiency)

            # appending KL divergence between proposal and true posterior
            w = result.samples["weights"]
            kl_divergence = np.mean(w * np.log(w))
            kl_divergence_variance = np.mean((w ** 2) * (np.log(w) ** 2)) - (kl_divergence ** 2)
            self.posterior_list.append_kl_divergence(var, kl_divergence, kl_divergence_variance)
            # TODO add method which appends SNR

            # add method which appends fisher information

    def sweep(self, template_fpath, outdir):
        """ 
        Parameters
        ----------
        template_fpath : str
            Path to a .ini file used by dingo pipe. These settings will be
            used to analyze the injection
        """

        # saving injection parameters for sweep 
        self.injection_parameters.to_csv(os.path.join(outdir, "injection_parameters.csv"), index=False)
        self.sweep_params.to_csv(os.path.join(outdir, "sweep_params.csv"), index=False)
        with open(os.path.join(outdir, "sampler_settings.json"), 'w') as f:
            json.dump(self.sampler_settings, f)

        # Iterate through the injection parameters and for each one generate a posterior
        for idx in self.injection_parameters.index:
            # Step 1: open the .ini file 
            with open(template_fpath, "r") as file:
                lines = file.readlines()

            # Step 2: Write to a new fpath 
            # TODO add a means to take the properties of the injection_generator and adjust
            # the ini file to match them
            new_fpath = os.path.join(outdir, f"{str(idx)}.ini")
            with open(new_fpath, "w+") as file:
                for line in lines:
                    if line.startswith("injection-dict"):
                        file.write(line.replace("_injection_dict", str(self.injection_parameters.iloc[idx].to_dict())))
                    elif line.startswith("label"):
                        file.write(line.replace("_label", str(idx)))
                    elif line.startswith("model-init"):
                        file.write(line.replace("_model_init.pt", self.sampler_settings["model_init_fpath"]))
                    elif line.startswith("model"):
                        file.write(line.replace("_model.pt", self.sampler_settings["model_fpath"]))
                    elif line.startswith("outdir"):
                        file.write(line.replace("_./outdir", f"./outdir_{str(idx)}"))
                    else:
                        file.write(line)
            
            # pipe the ini file
            command = ["dingo_pipe", new_fpath, "--local-generation"]
            output = subprocess.check_output(command, cwd=os.path.join(outdir))

            # submit the ini file
            command = ["condor_submit_dag", "-f", f"{outdir}/outdir_{idx}/submit/dag_{idx}.submit"]
            output = subprocess.check_output(command, cwd=outdir)

        # TODO add a method here which optionally hangs until all dags have finished running


class Bias1D(Bias):
    def __init__(self, load_dir = None, sweep_params = None, injection_parameters = None, sampler_settings = None):
        """ 
        Parameters
        ----------
        load_dir : str
            Folder from which to load the bias object
        sweep_params : pd.DataFrame
            DataFrame of values over which to sweep when generating injections
        injection_parameters : pd.DataFrame
            Injection parameters for which to evaluate the injections
        sampler_settings : dict
            Sampler settings. Should settings used for the sweep
         
        """
        if load_dir is not None:
            self.from_folder(load_dir)
        else:
            self.length = len(sweep_params)
            super().__init__(sampler_settings, injection_parameters)
            self.sweep_param_names = list(sweep_params.columns)
            self.sweep_params = sweep_params
            # self.check_prior(self.params)

            # defining injection parameters to iterate through
            new_df = self.injection_parameters
            new_df[self.sweep_params.columns] = self.sweep_params[self.sweep_params.columns]
            self.injection_parameters = new_df

    def from_folder(self, load_dir):
        """ 
        Parameters
        ----------
        load_dir : str
            Folder from which to load the bias object
         
        """
        self.sweep_params = pd.read_csv(os.path.join(load_dir, "sweep_params.csv"))
        self.sweep_param_names = list(self.sweep_params.columns)
        self.length = len(self.sweep_params)
        return super().from_folder(load_dir)

    def plot(self, ax, plot_param, plot_kwargs={"line": {}, "fill": {}, "truth": {}}, interval=0.9, x_values=None):

        # Adding a the sweep parameter on a line 
        if x_values is None:
            x_values = {
                "name": self.sweep_param_names[0],
                "array": [i[0] for i in self.posterior_list.master_dict.keys()]
            }

        if plot_param == "effective_sample_size" or plot_param == "sample_efficiency":
            # plotting ess numbers
            plot = np.array([self.posterior_list[idx]["ess"][plot_param] for idx in range(self.length)])
            out = ax.plot(x_values["array"], plot, **plot_kwargs["line"])

        else:
            # getting average and intervals of the posterior distributions
            avg = np.array([self.posterior_list.get_mean(idx)[plot_param] for idx in range(self.length)])
            interval = np.array([self.posterior_list.get_interval(idx, interval=interval)[plot_param] for idx in range(self.length)])
            truth = np.array([self.posterior_list[idx]["truth"][plot_param] for idx in range(self.length)])

            # setting plot properties
            ax.set_xlabel(x_values["name"])
            ax.set_ylabel(plot_param)
            ax.plot(x_values["array"], avg, **plot_kwargs["line"])
            ax.fill_between(x_values["array"], interval[:, 0], interval[:, 1], alpha=0.5, **plot_kwargs["fill"])

            out = ax.plot(x_values["array"], truth, label="Truth", **plot_kwargs["truth"])

        ax.set_xlabel(x_values["name"])
        ax.set_ylabel(plot_param)
        return out

    def save_frame(self, idx, fpath, x_values=None, **kwargs):

        truth = self.posterior_list[idx]["truth"]
        c = ChainConsumer()
        c.add_chain(
            {
                k: self.posterior_list[idx]["posteriors"][k].flatten()
                for k in self.posterior_list[idx]["posteriors"].keys()
            },
            **kwargs,
        )
        c.configure(
            linestyles=["-"],
            linewidths=[1.5],
            sigmas=[np.sqrt(2) * scipy.special.erfinv(x) for x in [0.5, 0.9]],
            shade=[False],
            shade_alpha=0.3,
            bar_shade=False,
            label_font_size=10,
            tick_font_size=10,
            usetex=False,
            legend_kwargs={"fontsize": 30},
        )

        tmp_result = self.sampler.to_result()
        prior = tmp_result.prior
        extents = {k: (v.minimum, v.maximum) for k, v in prior.items()}
        # Custom extents for some parameters 
        if "domega220" in list(extents.keys()):
            extents["domega220"] = (-0.8, 2)
        if "dtau220" in list(extents.keys()):
            extents["dtau220"] = (-0.8, 2)
        if "chirp_mass" in list(extents.keys()):
            extents["chirp_mass"] = (20, 40)

        fig = c.plotter.plot(
            truth=truth,
            extents=extents
        )

        # Adding a the sweep parameter on a line 
        if x_values is None:
            x_values = {
                "name": self.param_names[0],
                "array": [i[0] for i in self.posterior_list.master_dict.keys()]
            }
        num_plots = str(int(len(fig.axes) ** 0.5))
        sweep_ax = fig.add_subplot(int(num_plots*3))
        # sweep_ax.set_facecolor('r')
        y = 0 
        xmin = x_values["array"].min()
        xmax = x_values["array"].max()
        height = 1
        sweep_ax.set_xlim(xmin, xmax)
        sweep_ax.set_ylim(0, 10)
        sweep_ax.axhline(y=5, linestyle='-')
        sweep_ax.get_yaxis().set_visible(False)
        sweep_ax.scatter(x_values["array"][idx], 5, c='b', zorder=5, marker='x')
        sweep_ax.set_xlabel(x_values["name"])


        fig.set_figwidth(10)
        fig.set_figheight(10)
        fig.savefig(fpath, dpi=300)
        plt.close()

    def save_frames_for_video(self, outdir, x_values=None, **kwargs):
        os.makedirs(outdir, exist_ok=True)
        for idx in range(len(self.posterior_list)):
            self.save_frame(idx, outdir + f"/{idx:03d}", x_values=x_values, **kwargs)

        ret = f""" rsync -rav nihargupte@saraswati:{outdir}/* . && ffmpeg -y -r 5 -i %03d.png -c:v libx264 -vf "format=yuv420p,fps=7" out.mp4 """
        return ret

class Bias2D(Bias):
    def __init__(
        self, load_dir=None, sweep_params=None, injection_parameters=None, sampler_settings=None,
    ):
        """ 
        Parameters
        ----------
        load_dir : str
            Folder from which to load the bias object
        sweep_params : pd.DataFrame
            DataFrame of values over which to sweep when generating injections. Will create a
            grid according to the first two columns
        injection_parameters : pd.DataFrame
            Injection parameters for which to evaluate the injection 
        sampler_settings : dict 
            Dict of settings for the sampler
        """
        if load_dir is not None:
            self.from_folder(load_dir)
        else:
            self.length = len(sweep_params) ** 2
            super().__init__(sampler_settings, injection_parameters)
            self.sweep_params = sweep_params
            # self.check_prior(check_params)

            param1_arr, param2_arr = np.meshgrid(self.sweep_params.iloc[:, 0], self.sweep_params.iloc[:, 1])
            param1_arr, param2_arr = param1_arr.flatten(), param2_arr.flatten()

            new_df = self.injection_parameters
            new_df[self.sweep_params.columns[0]] = param1_arr
            new_df[self.sweep_params.columns[1]] = param2_arr
            self.injection_parameters = new_df

    def from_folder(self, load_dir):
        """ 
        Parameters
        ----------
        load_dir : str
            Folder from which to load the bias object
         
        """
        # assert keys of sweep and injections are the sam
        self.sweep_params = pd.read_csv(os.path.join(load_dir, "sweep_params.csv"))
        self.sweep_param_names = list(self.sweep_params.columns)
        self.length = len(self.sweep_params) ** 2
        return super().from_folder(load_dir)

    def plot(self, ax, plot_param, mode="average", plot_type="pcolormesh", **kwargs):
        ax.set_xlabel(self.sweep_params.columns[0])
        ax.set_ylabel(self.sweep_params.columns[1])
        x = self.posterior_list.keys_array

        if plot_param == "effective_sample_size" or plot_param == "sample_efficiency":
            Z = [self[i]["ess"][plot_param] for i in range(self.length)]

        elif plot_param == "kl_divergence" or plot_param == "kl_divergence_variance":
            Z = [self[i]["kl"][plot_param] for i in range(self.length)]

        elif mode == "average":
            pass

        elif mode == "median":
            pass 

        elif mode == "maxL":
            pass

        elif mode == "interval":
            pass

        else:
            raise Exception("Allowed modes are 'average', 'median', 'mode' and 'variance'")

        X, Y = x[:, 0], x[:, 1]
        if plot_type == "pcolormesh":
            xl = int(X.shape[0] / len(self.sweep_params))
            yl = int(Y.shape[0] / len(self.sweep_params))
            XX = np.reshape(X, (xl, xl))
            YY = np.reshape(Y, (yl, yl))
            ZZ = np.reshape(Z, (xl, yl))     
            divnorm = colors.TwoSlopeNorm(vmin=ZZ.min(), vcenter=0, vmax=ZZ.max())
            out = ax.pcolormesh(XX, YY, ZZ, norm=divnorm, **kwargs)
        elif plot_type == "tricontourf":
            out = ax.tricontourf(X, Y, Z, **kwargs)
        else:
            raise Exception(f"Plot type {plot_type} not supported")
        return out, ax
